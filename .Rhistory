getdata <- function(...)
{
e <- new.env()
name <- data(..., envir = e)[1]
e[[name]]
}
#variaveis para guardar e gravar no arquivo
it_g <-c()
bd_g <-c()
thrConf_g<-c()
nr_added_exs_g<-c()
for (i in 1:6){
print("organizando os dados")
if (i==1) {
#base de dados IRIS
base_original <- getdata("iris")
classe <- "Species"
}else if (i==2){
#base de dados ECOLI
base_original <- read.arff("ecoli.arff")
classe <- "class"
}
else if(i==3){
base_original <- read.arff("bupa.arff");
classe <- "selector"
}
else if(i==4){
base_original <- read.arff("glass.arff")
classe <- "Type"
}
else if(i==5){
base_original <- read.arff("haberman.arff")
classe <-"Survival_status"
}
else if(i==6){
base_original <-read.arff("pima.arff")
classe <- "class"
}
else if(i==7){
base_original <-read.arff("cleveland.arff")
classe <- "num"
}
#tentando usar filtro do weka para transformar dados nominais em binarios
#nombi <- make_Weka_filter("weka/filters/supervised/attribute/NominalToBinary") # creates an R interface to the WEKA filter
#datbin <- nombi(AT1 ~., data=base, control =Weka_control(N=TRUE, A=TRUE)) # Fehlermeldung
#datbin
#NÃO ESTÁ CERTO ASSIM, POIS ALGUNS EXEMPLOS NÃO ESTÃO SENDO USADOS NO TREINAMENTO NUNCA E OUTROS ESTÃO APARECENDO MAIS DE UMA VEZ
set.seed(100)
if (i==1){
indice_treinamento <- createDataPartition(base_original$Species, p=0.75, list=FALSE)
}else if (i==2){
indice_treinamento <- createDataPartition(base_original$class, p=0.75, list=FALSE)
}
base <- base_original[indice_treinamento,]
base_teste <- base_original[-indice_treinamento,]
#PRECISO RENUMERAR OS INDICES, TANTO DE TREINAMENTO QUANTO DE TESTE
setwd("C:\\local_R")
print("instalação dos pacotes")
#pacote que inclui: data splitting, pre-processing, feature selection, model tuning using resampling, variable importance estimation
#install.packages("caret")
#install.packages("caret", dependencies = c("Depends", "Suggests"))
#pacote que inclui self-training e outros algoritmos de aprendizado semisupervisionado
#install.packages("ssc")
#install.packages("DMwR")
#install.packages("caTools")
#install.packages("RWeka")
print("carregar os pacotes")
library("caret") #parece não ser necessário
library("ssc") #esse é obrigatório
library("plyr") #pacote q tem a função join_all
library("RWeka")
#USANDO A FUNÇÃO SELFTRAIN (USADA POR ALEXANDRE)
library("DMwR2")
library("DMwR")
library("datasets")
print("Função para pegar a base de dados e colocar em uma variável base")
getdata <- function(...)
{
e <- new.env()
name <- data(..., envir = e)[1]
e[[name]]
}
#variaveis para guardar e gravar no arquivo
it_g <-c()
bd_g <-c()
thrConf_g<-c()
nr_added_exs_g<-c()
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
probPreds
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
probPreds
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
probPreds
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
source('C:/Users/karliane/Dropbox/doutorado/tese/experimentos/scripts/segunda tentativa - unirotulo/experimentos_karliane_implementando_self_train.R', echo=TRUE)
source('C:/local_R/projeto_karliane/scripts_comuns/funcoes.R')
?selfTrain
??selfTrain
data(iris)
xl<-iris[,1:4]
xl
yl<-rep(1:3,each=20)
yl
?rep
known.label <-c(1:20,51:70,101:120)
known.label
xu<-xl[-known.label,]
xu
xl<-xl[known.label,]
xl
a <- data("iris")
a
a <- data(iris)
a
iris
xu<-xl[-known.label,]
xl<-xl[known.label,]
yu<-sslCoTrain(xl,yl,xu,method1="xgb",nrounds1 = 100,method2="xgb",nrounds2 = 100,n=60)
install.packages("ssl")
library(ssl)
install.packages("ssl")
library("ssl")
install.packages("SSL")
library("SSL")
install.packages("SSL")
install.packages("SSL")
yu<-sslCoTrain(xl,yl,xu,method1="xgb",nrounds1 = 100,method2="xgb",nrounds2 = 100,n=60)
install.packages("SSL")
install.packages("SSL")
?SSL
??SSL
install.packages("SSL")
install.packages("caret")
library("caret")
install.packages("DMwR2")
library("DMwR2")
install.packages("SSL")
library("SSL")
install.packages("SSL", dependencies = c("Depends", "Suggests"))
library("SSL")
install.packages("graph")
library("SSL")
install.packages("graph")
library("SSL")
library("graph")
install.packages("graph")
install.packages("SSL", dependencies = c("Depends", "Suggests"))
library("SSL")
library("graph")
?ssc
??ssc
install.packages("graph")
# install.packages("caret")
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages("SSL", dependencies = c("Depends", "Suggests"))
install.packages("graph")
library("caret")
library("SSL")
install.packages("SSL", dependencies = c("Depends", "Suggests"))
library("SSL")
install.packages("graph", dependencies = c("Depends", "Suggests"))
install.packages("graph", dependencies = c("Depends", "Suggests"))
install.packages("NetPreProc")
install.packages("Rcpp")
install.packages("caret")
install.packages("proxy")
install.packages("xgboost")
install.packages("klaR")
install.packages("e1071")
install.packages("SSL", dependencies = c("Depends", "Suggests"))
install.packages(c("actuar", "adabag", "agricolae", "AICcmodavg", "ape", "argparse", "aws.s3", "bayesplot", "BayesXsrc", "bbmle", "bdsmatrix", "BH", "bibtex", "bigmemory", "bindr", "bindrcpp", "binGroup", "BMA", "BradleyTerry2", "brms", "broom", "BSDA", "btergm", "C50", "candisc", "car", "CARBayes", "cba", "chron", "circlize", "coin", "corrplot", "covr", "coxme", "crayon", "cubature", "Cubist", "curl", "d3heatmap", "data.table", "date", "DBI", "DBItest", "degreenet", "deldir", "dendextend", "denstrip", "descr", "DescTools", "deSolve", "devtools", "DiagrammeR", "digest", "DoE.base", "doParallel", "dplyr", "DT", "earth", "effects", "ellipse", "Epi", "EpiModel", "ergm", "estimability", "evaluate", "fastICA", "fastR", "fBasics", "fGarch", "fields", "foreach", "forecast", "Formula", "fTrading", "gamlss", "gamlss.dist", "gamm4", "gapminder", "gdata", "GenSA", "geoRglm", "geosphere", "GGally", "glmmML", "glmnet", "GlobalOptions", "glue", "gmm", "gridExtra", "gstat", "heatmaply", "heplots", "hexbin", "Hmisc", "hms", "HSAUR", "HSAUR3", "htmltools", "htmlwidgets", "httpuv", "httr", "hunspell", "igraph", "iterators", "janeaustenr", "jsonlite", "kangar00", "knitcitations", "knitr", "ks", "LaF", "Lahman", "latentnet", "lazyeval", "lfe", "lintr", "listviewer", "lme4", "lmerTest", "lmodel2", "lsmeans", "lubridate", "magick", "mapdata", "mapproj", "maps", "MBESS", "mboost", "mclust", "MCMCglmm", "MCMCpack", "mda", "mediation", "memisc", "mgcv", "mice", "microbenchmark", "mix", "mldr", "mosaic", "mosaicData", "multcomp", "MuMIn", "mvtnorm", "nanotime", "nlme", "NLP", "NMF", "np", "orcutt", "pander", "party", "partykit", "PBSmapping", "pdftools", "PerformanceAnalytics", "pgirmess", "plm", "plogr", "plotly", "plotmo", "plotrix", "prefmod", "pROC", "pryr", "pscl", "psych", "purrr", "quantmod", "quantreg", "qvcalc", "R.rsp", "R2BayesX", "R6", "randomForest", "RANN", "raster", "rasterVis", "Rcmdr", "RcmdrMisc", "RcppEigen", "RCurl", "readr", "registry", "rem", "reshape", "reshape2", "rgdal", "rgenoud", "rgeos", "rgl", "rJava", "rmarkdown", "rmeta", "Rmpfr", "rms", "RMySQL", "robustbase", "RPostgreSQL", "rprojroot", "rsm", "RSQLite", "rstan", "rstanarm", "rstantools", "rstudioapi", "rticles", "rugarch", "RWeka", "RWekajars", "sampleSelection", "sandwich", "scales", "scatterplot3d", "seriation", "sfsmisc", "shape", "shiny", "shinystan", "SimComp", "snowFT", "sourcetools", "sp", "spam", "spatstat", "spatstat.utils", "spdep", "spls", "ssc", "stabs", "StanHeaders", "statnet.common", "stringi", "stringr", "subselect", "survival", "svglite", "tables", "tergm", "testit", "testthat", "tibble", "tidyr", "tidyverse", "tikzDevice", "timeDate", "timeSeries", "tis", "tm", "tseries", "TTR", "tufte", "vcd", "vcdExtra", "vdiffr", "viridis", "viridisLite", "wbstats", "webshot", "webutils", "wordcloud2", "XML", "xml2", "xts", "yaml", "Zelig", "zoo"))
install.packages("caret")
install.packages("proxy") #mesmo problema do graph
source("https://bioconductor.org/biocLite.R")
biocLite("graph")
install.packages("SSL", dependencies = c("Depends", "Suggests"))
library("SSL")
install.packages("NetPreProc")
install.packages("Rcpp")
install.packages("caret")
install.packages("SSL")
data(iris)
xl<-iris[,1:4] #a base dados iris sem os rotulos
#Suppose we know the first twenty observations of each class
#and we want to predict the remaining with co-training
# 1 setosa, 2 versicolor, 3 virginica
yl<-rep(1:3,each=20) #armazena em yl os números 1,2,3 (classes) 20 vezes - são os rotulos conhecidos
known.label <-c(1:20,51:70,101:120) # id dos exemplos com rótulos conhecidos
xu<-xl[-known.label,] # exemplos com rotulos desconhecidos
xl<-xl[known.label,] # exemplos com rotulos conhecidos
yu<-sslCoTrain(xl,yl,xu,method1="xgb",nrounds1 = 100,method2="xgb",nrounds2 = 100,n=60)
?SSL
source("https://bioconductor.org/biocLite.R")
biocLite("graph")
install.packages("SSL")
library("SSL")
install.packages("prodlim")
library("SSL")
install.packages("proxy") #mesmo problema do graph
install.packages("NetPreProc")
install.packages("Rcpp")
install.packages("xgboost")
install.packages("klaR")
install.packages("e1071")
install.packages("prodlim")
source("https://bioconductor.org/biocLite.R")
biolite("proxy")
bioclite("proxy")
biocLite("graph")
biocLite("proxy")
install.packages("SSL")
library("SSL")
install.packages("purrr")
library("SSL")
data(iris)
xl<-iris[,1:4] #a base dados iris sem os rotulos
#Suppose we know the first twenty observations of each class
#and we want to predict the remaining with co-training
# 1 setosa, 2 versicolor, 3 virginica
yl<-rep(1:3,each=20) #armazena em yl os números 1,2,3 (classes) 20 vezes - são os rotulos conhecidos
known.label <-c(1:20,51:70,101:120) # id dos exemplos com rótulos conhecidos
xu<-xl[-known.label,] # exemplos com rotulos desconhecidos
xl<-xl[known.label,] # exemplos com rotulos conhecidos
yu<-sslCoTrain(xl,yl,xu,method1="xgb",nrounds1 = 100,method2="xgb",nrounds2 = 100,n=60)
yu
yu <- NULL
num.class <- length(unique(yl)) + 1
num.class
dim(xu)
dim(xu)[1]
yl <- as.factor(yl)
YL
yl
seed
set.seed(seed)
data(iris)
xl<-iris[,1:4] #a base dados iris sem os rotulos
#Suppose we know the first twenty observations of each class
#and we want to predict the remaining with co-training
# 1 setosa, 2 versicolor, 3 virginica
yl<-rep(1:3,each=20) #armazena em yl os números 1,2,3 (classes) 20 vezes - são os rotulos conhecidos
known.label <-c(1:20,51:70,101:120) # id dos exemplos com rótulos conhecidos
xu<-xl[-known.label,] # exemplos com rotulos desconhecidos
xl<-xl[known.label,] # exemplos com rotulos conhecidos
yu<-sslCoTrain(xl,yl,xu,method1="xgb",nrounds1 = 100,method2="xgb",nrounds2 = 100,n=60)
data(iris)
xl<-iris[,1:4] #a base dados iris sem os rotulos
#Suppose we know the first twenty observations of each class
#and we want to predict the remaining with co-training
# 1 setosa, 2 versicolor, 3 virginica
yl<-rep(1:3,each=20) #armazena em yl os números 1,2,3 (classes) 20 vezes - são os rotulos conhecidos
known.label <-c(1:20,51:70,101:120) # id dos exemplos com rótulos conhecidos
xu<-xl[-known.label,] # exemplos com rotulos desconhecidos
xl<-xl[known.label,] # exemplos com rotulos conhecidos
yu<-sslCoTrain(xl,yl,xu,method1="xgb",nrounds1 = 100,method2="xgb",nrounds2 = 100,n=60)
debugSource('C:/local_R/projeto_karliane/co_training/testanto sslCoTrain.R', echo=TRUE)
seed
seed
seq
x1
y1
floor(n/2)
dim(xu)[1]
?floor
floor(n/2)
yu
xl
yl
n - floor(n/2)
dim(xu)[1]
n - floor(n/2)
yu
?sslCoTrain
library("SSL")
#carregando todos os pacotes do self-training
library("ggplot2")
library("caret") #parece nao ser necessario
library("ssc") #esse eh obrigatorio
library("plyr") #pacote q tem a funcao join_all
library("DMwR2")
library("DMwR")
library("caTools")
library("RWeka")
library("rminer")
library("datasets")
library("e1071")
#coBC e/ou coBCG
#https://www.rdocumentation.org/packages/ssc/versions/2.0.0/topics/coBCG
#testando o coBC
data(wine)
cls <- which(colnames(wine) == "Wine")
cls
wine
colnames(wine)
colnames(wine) == "Wine"
which(colnames(wine) == "Wine")
?which
x <- wine[, -cls] # instances without classes
y <- wine[, cls] # the classes
x
y
x <- scale(x) # scale the attributes
x
?scale
## Prepare data
set.seed(20)
?sample
# Use 50% of instances for training
tra.idx <- sample(x = length(y), size = ceiling(length(y) * 0.5))
xtrain <- x[tra.idx,] # training instances
ytrain <- y[tra.idx] # classes of training instances
# Use 70% of train instances as unlabeled set
tra.na.idx <- sample(x = length(tra.idx), size = ceiling(length(tra.idx) * 0.7))
ytrain[tra.na.idx] <- NA # remove class information of unlabeled instances
?setdiff
1:length(y)
tra.idx
# Use the other 50% of instances for inductive testing
tst.idx <- setdiff(1:length(y), tra.idx) #seta a diferenca entre o tamanho de y e as instancias de treinamento
tst.idx
xitest <- x[tst.idx,] # testing instances
yitest <- y[tst.idx] # classes of testing instances
xitest
yitest
y
## Example: Training from a set of instances with 1-NN as base classifier.
set.seed(1)
m1 <- coBC(x = xtrain, y = ytrain,
learner = caret::knn3,
learner.pars = list(k = 1),
pred = "predict")
m1 <- coBC(x = xtrain, y = ytrain,
learner('IBk',list(control = Weka_control(K=15, X=TRUE))),
#learner = caret::knn3,
learner.pars = list(k = 1),
pred = "predict")
m1 <- coBC(x = xtrain, y = ytrain,
learner('IBk',list(control = Weka_control(K=15, X=TRUE))),
#learner = caret::knn3,
#learner.pars = list(k = 1),
pred = "predict")
m1 <- coBC(x = xtrain, y = ytrain,
learner('IBk',list(control = Weka_control(K=15, X=TRUE)))
#learner = caret::knn3,
#learner.pars = list(k = 1),
#pred = "predict"
)
debugSource('C:/local_R/projeto_karliane/co_training/testanto sslCoTrain.R', echo=TRUE)
debugSource('C:/local_R/projeto_karliane/co_training/testanto sslCoTrain.R', echo=TRUE)
ENV
env
denv
env$x
x
env$bclassif
class(env$bclassif)
debugSource('C:/local_R/projeto_karliane/co_training/testanto sslCoTrain.R', echo=TRUE)
debugSource('C:/local_R/projeto_karliane/co_training/testanto sslCoTrain.R', echo=TRUE)
m1 <- coBC(x = xtrain, y = ytrain,
#learner('IBk',list(control = Weka_control(K=15, X=TRUE)))
learner = ssc::oneNN,
#learner = caret::knn3,
learner.pars = list(k = 1),
pred = "predict"
)
m1 <- coBC(x = xtrain, y = ytrain,
#learner('IBk',list(control = Weka_control(K=15, X=TRUE)))
learner = ssc::oneNN
#learner = caret::knn3,
#learner.pars = list(k = 1),
#pred = "predict"
)
m1 <- coBC(x = xtrain, y = ytrain,
#learner('IBk',list(control = Weka_control(K=15, X=TRUE)))
#learner = ssc::oneNN
learner = e1071::svm()
#learner = caret::knn3,
#learner.pars = list(k = 1),
#pred = "predict"
)
m1 <- coBC(x = xtrain, y = ytrain,
#learner('IBk',list(control = Weka_control(K=15, X=TRUE)))
#learner = ssc::oneNN
learner = e1071::svm
#learner = caret::knn3,
#learner.pars = list(k = 1),
#pred = "predict"
)
m1 <- coBC(x = xtrain, y = ytrain,
#learner('IBk',list(control = Weka_control(K=15, X=TRUE)))
#learner = ssc::oneNN
learner(e1071::svm)
#learner = caret::knn3,
#learner.pars = list(k = 1),
#pred = "predict"
)
m1 <- coBC(x = xtrain, y = ytrain,
#learner('IBk',list(control = Weka_control(K=15, X=TRUE)))
#learner = ssc::oneNN
e1071::svm
#learner = caret::knn3,
#learner.pars = list(k = 1),
#pred = "predict"
)
?predict
library("SSL")
library("caret") #parece nao ser necessario
source('C:/local_R/projeto_karliane/co_training/scripts_comuns/configuracoes_co_training.R', echo=TRUE)
base_original <- read.arff("bupa.arff");
bd_nome <- "bupa"
taxa <- 5
classe <- "class"
source('C:/local_R/projeto_karliane/scripts_comuns/organiza_dados.R')
data <- base_treino_self_training
form <- as.formula(paste(classe,'~', '.'))
learner <- learner("naiveBayes", list(4))
predFunc <- 'func'
thrConf <- 0.9
#rodar func, f1 e f2
#--- até aqui
N <- NROW(data)
source('C:/local_R/projeto_karliane/scripts_comuns/organiza_dados.R')
#roda esses comandos somente quando não chamar a funcao
source('C:/local_R/projeto_karliane/co_training/scripts_comuns/configuracoes_co_training.R')
base_original <- read.arff("bupa.arff");
bd_nome <- "bupa"
taxa <- 5
classe <- "class"
source('C:/local_R/projeto_karliane/scripts_comuns/organiza_dados.R')
print("organizando os dados")
set.seed(214)# garante que o conjunto de dados escolhido para treinamento ser? sempre o mesmo - n?o sei se preciso dessa garantia
#conta a quantidade de exemplos da base de dados completa
exemplos = NROW(base_original) #TAVA nrow
#comando que retorna a quantidade de exemplos em cada uma das classes
qtd_exem_por_classe <- ddply(base_original,~class,summarise,number_of_distinct_orders=length(class))
qtd_exem_por_classe <- ddply(base_original,~class,summarise,number_of_distinct_orders=length(class))
base_original
debugSource('C:/local_R/projeto_karliane/scripts_comuns/organiza_dados.R', echo=TRUE)
debugSource('C:/local_R/projeto_karliane/scripts_comuns/organiza_dados.R', echo=TRUE)
debugSource('C:/local_R/projeto_karliane/scripts_comuns/organiza_dados.R', echo=TRUE)
#comando que retorna 10% da quantidade de exemplos da classe com menor número de instâncias
qtd_exem_menor_classe <- trunc(min(qtd_exem_por_classe$number_of_distinct_orders)*0.1)
#criação dos conjuntos de treinamento e teste
#o holdout cria dois conjuntos: 1) H$tr com o id de 75% dos exemplos para treinamento e 2) H$ts com id de 25% dos eemplos para teste
H <- holdout(base_original$class, ratio = 0.75, mode="stratified")
base <- base_original[H$tr,]
base_teste <- base_original[H$ts,]
#variável que armazena os exemplos inicialmente routlados, será usado para treinamento supervisionado
treinamento <<- base_rotulada_treino <- base_original[H$tr,]
#sorteando os exemplos que ficarão rotulados inicialmente
H2 <- holdout(base$class, ratio = (taxa/100), mode="stratified")
ids_treino_rot <- H2$tr #ids dos exemplos que iniciarão rotulados
#retirando o rótulo dos exemplos que iniciarão o treinamento sem rótulo
base[-ids_treino_rot,"class"] <- NA
#atribuindo a variável base_treino_self_training a base de dados semissupervisionada
base_treino_self_training<-base
#guardando os exemplos inicialmente rotulados
base_rotulados_ini <-base[ids_treino_rot,]
data <- base_treino_self_training
form <- as.formula(paste(classe,'~', '.'))
learner <- learner("naiveBayes", list(4))
predFunc <- 'func'
thrConf <- 0.9
#rodar func, f1 e f2
#--- até aqui
N <- NROW(data)
data <- base_treino_self_training
form <- as.formula(paste(classe,'~', '.'))
learner <- learner("naiveBayes", list(4))
predFunc <- 'func'
thrConf <- 0.9
#rodar func, f1 e f2
#--- até aqui
N <- NROW(data)
#primeiramente se faz necessario particionar os dados, ou seja, criar duas visoes
col <- (ncol(data)-1)/2 #PENSAR COMO FAZER SE O NUMERO DE COLUNAS FOR IMPAR.
xl <- data[,1:ncol(data)-1] #a base dados iris sem os rotulos
yl <- data[-(1:ncol(data)-1)] #rotulos da base iris
view <- partition.matrix(xl, rowsep = nrow(data), colsep = c(col,col))
xl
col
data
base_treino_self_training
base
ids_treino_rot
base_original
H$tr
H$tr,
H
H <- holdout(base_original$class, ratio = 0.75, mode="stratified")
H
debugSource('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
debugSource('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
debugSource('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
source('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
source('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
source('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
source('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
debugSource('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
nrow(data)
nrow(sup1)
nrow(sup2)
length(sup1)
length(sup2)
debugSource('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
source('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
source('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
source('C:/local_R/projeto_karliane/co_training/script_main_co_training.R', echo=TRUE)
